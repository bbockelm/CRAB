[CRAB]
#
#   This section contains the default values for general parameters.
#   They can be set also as a command-line option, i.e.
#
#   key1 = value1
#   [SECTION]
#   key2 = value2
#
#   in this section corresponds to
#
#   crab.py -key1=value1 -key2=SECTION.value2
#
#   in the command line.
#
jobtype = cmssw
#jobtype = orca
#jobtype = famos
scheduler = edg 

[CMSSW]

### The data you want to access (to be found on DBS) 
### /primarydataset/datatier/processeddataset
### can be "None" for no input
datasetpath=/PreProdR3Minbias/SIM/GEN-SIM
#datasetpath=None

### The ParameterSet you want to use
pset=readPSetTrivial.cfg
#pset=pythia.cfg

### Set 2 of the 3 following job splitting options
### Total number of events to be accessed: -1 means all 
### ("-1" is not usable if no input)
total_number_of_events=2000

### Number of events to be processed per job
events_per_job = 1000

### Number of jobs
#number_of_jobs = 10

### The output files produced by your application (comma separated list)
output_file = myroot.root

[ORCA]
###############################
####### DATA TO ANALYZE #######
###############################

## CERN
#dataset = bt03_qcd50-80_2tauj
#owner = bt_2x1033PU761_TkMu_g133_CMS

## CNAF
dataset = bt03_ttH120_6j1l
owner = bt_DST871_2x1033PU_g133_CMS

## PIC
#dataset = hg03b_hww_2l_140
#owner = hg_DST871_2x1033PU_g133_CMS

## FNAL
# dataset = eg03_tt_2e2mu 
# owner = eg_DST871_2x1033PU_g133_CMS

## LNL
#dataset = mu03_W1mu 
#owner = mu_DST861_2_3_2x1033PU_g132_CMS

#dataset = mu03_W1mu
#owner = mu_DST861_2_3_2x1033PU_g132_CMS

## BA
#dataset = bt03_tt_pureleptonic_etau
#owner = bt_DST871_2x1033PU_g133_CMS

#dataset = mu04_DY2mu_Mll1500
#owner = mu_DST871_2x1033PU_g133_OSC

### Data Tier to be accessed.
### Possible candidates are: DST, Digi, Hit (Comma separated list, mind the case!)
#data_tier = DST,Digi,Hit
data_tier = DST

### Order of the catalogs on .orcarc : do not change unless you know what you are doing!
#order_catalogs = 

###############################
### JOB EVENTS/JOB SPLITTING ##
###############################

## First event to analyze: default is 0
#first_event = 0

## Total number of events to analyze: -1==all
total_number_of_events = 100

## Number of events for each job
job_number_of_events = 10

### Total number of jobs to be created: incompatible with previous "job_number_of_events"
#total_number_of_jobs = 100

###############################
####### ORCA EXECUTABLE #######
###############################

## User must provide the executable into his personal scram area
executable = ExDSTStatistics

## or the script that calls the executable...
#script_exe = /home/fanzago/CRAB/UserTools/src/orca_script.sh

## Output files produced by executable: comma separated list, can be empty but mut be present!
output_file = dststatistics.aida


###############################
########## ORCA CARD ##########
###############################

## orcarc card provided by user (if not in current directory, the full path
## must to be provided) NB the file must exist (could be empty)
orcarc_file = orca_orcarc.main


[FAMOS]

###############################
###### FAMOS INPUT DATA #######  
###############################

### LFN of the input file registered into the LFC catalog
input_lfn = georgia/su05_pyt_lm6.ntpl

### number of events per ntuple
events_per_ntuple = 250

### LFN for the input pile-up ntuples (already registered to LFC) 
input_pu_lfn = gia/mu05b_MBforPU_20200000.ntpl

### number of pile-up ntuples accessed per job
number_pu_ntuples = 2
###############################
###### FAMOS EXECUTABLE #######
###############################

## User must provide the executable into his personal scram area
executable = ExRootAnalysisFamos

## or the script that calls the executable...
#script_exe = /home/fanzago/CRAB/UserTools/src/orca_script.sh

## Output files produced by executable: comma separated list, can be empty but mut be present!
output_file = test.root


###############################
########## FAMOS CARD ##########
###############################

## orcarc card provided by user (if not in current directory, the full path
## must to be provided) NB the file must exist (could be empty)
orcarc_file = famos_orcarc.main

###############################
### JOB EVENTS/JOB SPLITTING ##
###############################

## First event to analyze: default is 0
#first_event = 0

## Total number of events to analyze: -1==all
total_number_of_events = 100

## Number of events for each job
job_number_of_events = 10

### Total number of jobs to be created: incompatible with previous "job_number_of_events"
#total_number_of_jobs = 100


[USER]
################################
#### additional input file #####
################################

## files to be put in InputSandBox, with full path: comma separated list
#additional_input_files = /home_local/fanzago/fede.txt, /home_local/fanzago/fede.prova


#################################
######### CRAB  DIR  ############
#################################

## Name of UI directory where CRAB will create job to submit (with full path).
## If commented, the default directory will be "crab_0_data_time"
#ui_working_dir = /full_path/mu03_DY2mu
#ui_working_dir : /full_path/%(dataset)s

#################################
#### JOB OUTPUT MANAGEMENT #####
#################################

### RETRIEVE JOB OUTPUT INTO UI ###
## to have back the job executable output into UI (return_data= 1)
return_data = 1

### If return_data = 1 ###
## UI directory where to store the CMS executable output
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#outputdir=/home/fanzago/CRAB/Crab/python/out_orca

### If return_data = 1 ###
## UI directory where to store the stderr, stdout and .BrokerInfo of submitted jobs
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#logdir=/home/fanzago/CRAB/UserTools/src/grid_job_log

### COPY JOB OUTPUT INTO A SE ###
## if you want to copy the CMS executable output into a SE (i:e castor)
### WARNING: if the copy fails and return_data = 0, the output is lost
#copy_data = 1

### if copy_data = 1 ###
## name of the SE where to copy the CMS executable output.
#storage_element = castorgrid.cern.ch
## and the SE directory (or the mountpoint) that has to be writable from all
#storage_path = /castor/cern.ch/user/u/user

### REGISTER JOB OUTPUT IN THE LFC CATALOG ###
## if you want also to register the CMS executable output into the LFC catalog
## WARNING: to use with copy_data = 1
#register_data = 1

### if register_data = 1
## If you register the CMS output file into the LFC catalog, this is the first part of LFN
### example LFN="lfn_dir"/"output_file"
#lfn_dir = MyDirLFN 

#################################
####### JOB MONITORING  ### #####
#################################


### Use central BOSS DB instead of one for each task: the DB must be already been setup!
use_central_bossDB = 0

### Use Boss RealTime monitoring
use_boss_rt = 1 


[EDG]
################################
###### EDG specific stuff ######
################################

# LCG middleware version installed on testbed
lcg_version = 2

## to change the CMS-broker RB (download these files from crab web page)
#config_vo = /home/fanzago/edg_wl_ui.conf.CMS_CERN
#config = /home/fanzago/edg_wl_ui_cmd_var.conf.CMS_CERN

## to change the CMS-broker RB. The ones available for CMS are "CERN" and "CNAF": the configuration
## files needed to change the broker will be automatically downloaded from CRAB web page. If the
## files are already present on the working directory they will be used. 
#rb = CNAF

## CMS myproxy server, to proxy delegation
proxy_server = myproxy.cern.ch 


## to add other requirements to jdl file, as example the Operating System
#requirements = (other.GlueHostOperatingSystemName == "RedHat")

## cpu time and wall_clock_time(=real time) in minutes. Written into the jdl file
#max_cpu_time = 60
#max_wall_clock_time = 60

## CE Black List: all the CE whose name contains the following strings (comma
## separated list) will not be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
#ce_black_list = edu

## CE White List: only the CE whose name contains the following strings (comma
## separated list) will be considered for submission.
## Use the dns domain (eg fnal, cern, ifae, fzk, cnaf, lnl,....)
#ce_white_list = infn

## fields written into jdl
virtual_organization = cms

## number or retry count
retry_count = 2

## LFC catalog parameters
lcg_catalog_type = lfc
lfc_host = lfc-cms-test.cern.ch
lfc_home = /grid/cms
