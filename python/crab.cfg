[CRAB]
#
#   This section contains the default values for general parameters.
#   They can be set also as a command-line option, i.e.
#
#   key1 = value1
#   key2 = value2
#
#   in this section corresponds to
#
#   crab.py -key1=value1 -key2=value2
#
#   in the command line.
#
create = 0

jobtype = orca
scheduler = edg

[USER]
dataset = mu03_DY2mu
owner = mu_DST871_2x1033PU_g133_CMS

### dataset and owner to analyze
# dataset = sm05_st_s_lvb
# owner = sm_DST8713_2x1033PU_g133_OSC
#dataset = eg03_gamjet
#owner = eg_2x1033PU761_TkMu_g133_CMS

## CERN
# dataset = bt03_qcd50-80_2tauj
# owner = bt_2x1033PU761_TkMu_g133_CMS

## CNAF
# dataset = bt03_ttH120_6j1l
# owner = bt_DST871_2x1033PU_g133_CMS

## PIC
#dataset = hg03b_hww_2l_140
#owner = hg_DST871_2x1033PU_g133_CMS
# dataset = hg03b_hww_2l_165 
# owner = hg_DST871_2x1033PU_g133_CMS

## FNAL
# dataset = eg03_tt_2e2mu 
# owner = eg_DST871_2x1033PU_g133_CMS

## LNL
# dataset = mu05_cosmic_surface_bfield_off
# owner = mu_NoPU871_TkMu_2_g133_OSC
# dataset = mu03_bb2mu
# owner = mu_DST871_2x1033PU_g133_CMS
# dataset = mu03_tt2mu
# owner = mu_DST871_2x1033PU_g133_OSC
# dataset = mu03_W1mu 
# owner = mu_DST861_2_3_2x1033PU_g132_CMS

## BA
# dataset = bt03_tt_pureleptonic_etau
# owner = bt_DST871_2x1033PU_g133_CMS


### User must provide the executable into his personal scram area 
#executable = ExDigiStatistics
executable = ExDSTStatistics

### Data Tier to be accessed.
### Possible candidates are: DST, Digi, Hit (Comma separated list, mind the case!)
### The data tier corresponding to the requested owner is the default, other
### Tier (parents) can be accessed provided they are published in the same site as
### primaty data tier. MCInfo are inside Hit
data_tier = DST,Digi,Hit
#data_tier = Digi,Hit

### orcarc card provided by user (if not into current directory, the full path
### must to be provided) NB the file must exist (could be empty)
orcarc_file = orcarc.main

### First event to analyze: default is 0
#first_event = 100
### Total number of events to analyze: -1==all
total_number_of_events = -1
### Number of events for each job
#job_number_of_events = 1000
### Total number of jobs to be created: incompatible with previous "job_number_of_events"
total_number_of_jobs = 100

### Output files produced by executable: these files will be bring back by
### autoretrieve/monitor command.
### Comma separated list, can be empty but mut be present!
output_file = dststatistics.aida

### additional files to be put in InputSandBox and sent with the jobs
### a comma separated list
#additional_input_files =

### Name of directory where crab will create job to submit.
### If commented, the default directory will be "crab_0_data_time"
#ui_working_dir = mu03_DY2mu
#ui_working_dir : %(dataset)s

### directory where to put the GRID job output (if option monitor|autoretrieve is used)
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#outputdir=PIC
### ditto for log
#logdir=PIC

# specify how to build exe/libs: tgz -- from user's tarball
build_mode = tgz
### name of executable archive. If empty, "default.tgz" is used
tgz =

### SE subdirectory where to put the produced output 
### (subdirectory into the directory where "CMS" can write):
### used only with -register_data option
### example: name_of_SE/mountpoint_for_cms/output_storage_subdir/output_file 
#output_storage_subdir = fede/orca/26_11_2004/

### JAM monitoring ###
### jam perl to send in InputSandbox:
#run_jam = send.pl
### name of output of JAM:
#output_jam = ciao

[EDG]
#
#   This section contains EDG specific stuff.
#
# LCG middleware version installed on testbed
lcg_version = 2

# fields written into jdl
virtual_organization = cms 
retry_count = 0

# in order to change RB and LB 
config_vo = edg_wl_ui.conf.CMS_CNAF
config = edg_wl_ui_cmd_var.conf.CMS_CNAF

### Default storage element and path to save produced data.
#storage_element = gridit002.pd.infn.it
#storage_path = /flatfiles//SE00/cms/
